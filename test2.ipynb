{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ea7e56-6562-4b7f-a591-ca2875378f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0461 - loss: 3.5299\n",
      "Epoch 2/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.2202 - loss: 2.5812\n",
      "Epoch 3/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4037 - loss: 1.8426\n",
      "Epoch 4/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5213 - loss: 1.4828\n",
      "Epoch 5/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5650 - loss: 1.2947\n",
      "Epoch 6/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5997 - loss: 1.1943\n",
      "Epoch 7/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6384 - loss: 1.0730\n",
      "Epoch 8/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6579 - loss: 0.9866\n",
      "Epoch 9/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6691 - loss: 0.9492\n",
      "Epoch 10/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6950 - loss: 0.8721\n",
      "Epoch 11/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7102 - loss: 0.8380\n",
      "Epoch 12/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7365 - loss: 0.7584\n",
      "Epoch 13/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7489 - loss: 0.7237\n",
      "Epoch 14/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7608 - loss: 0.7117\n",
      "Epoch 15/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7433 - loss: 0.7047\n",
      "Epoch 16/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7751 - loss: 0.6343\n",
      "Epoch 17/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7961 - loss: 0.5912\n",
      "Epoch 18/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8093 - loss: 0.5581\n",
      "Epoch 19/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8177 - loss: 0.5185\n",
      "Epoch 20/20\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8384 - loss: 0.4928\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f21d199b600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Original Characters: 7WK\n",
      "Predicted Characters: 2J2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Character-to-index mapping for digits 0-9 and letters A-Z\n",
    "chars = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "char_to_index = {char: idx for idx, char in enumerate(chars)}\n",
    "\n",
    "\n",
    "def generate_training_data(chars='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ', num_samples=100, output_dir='training_data'):\n",
    "    \"\"\"Generate synthetic images of characters 0-9 and A-Z with random padding, rotation, and noise.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for char in chars:\n",
    "        for i in range(num_samples):\n",
    "            # Create a blank image (28x28)\n",
    "            img = np.zeros((28, 28), dtype=np.uint8)\n",
    "            \n",
    "            # Apply random padding (max 5 pixels)\n",
    "            top_padding = random.randint(0, 5)\n",
    "            bottom_padding = random.randint(0, 5)\n",
    "            left_padding = random.randint(0, 5)\n",
    "            right_padding = random.randint(0, 5)\n",
    "            \n",
    "            # Ensure padding does not exceed image dimensions\n",
    "            img = cv2.copyMakeBorder(img, top_padding, bottom_padding, left_padding, right_padding, cv2.BORDER_CONSTANT, value=(0))\n",
    "            \n",
    "            # Draw the character on the padded image\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            char_size = cv2.getTextSize(char, font, 1, 2)[0]\n",
    "            \n",
    "            # Ensure y position is within a valid range\n",
    "            y_min = char_size[1] + 5  # Minimum y position (to avoid text being cut off)\n",
    "            y_max = img.shape[0] - 5  # Maximum y position (to avoid text going out of bounds)\n",
    "            y = random.randint(0, 20)\n",
    "            \n",
    "            # Ensure x position doesn't cause the text to go out of bounds\n",
    "            x = random.randint(5, 20)\n",
    "            \n",
    "            cv2.putText(img, char, (x, y), font, 1, (255,), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Apply random rotation\n",
    "            angle = random.randint(-10, 10)  # Rotate between -10 and 10 degrees\n",
    "            M = cv2.getRotationMatrix2D((img.shape[1] // 2, img.shape[0] // 2), angle, 1)\n",
    "            img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "            \n",
    "            # Apply random noise\n",
    "            noise = np.random.normal(0, 10, img.shape)  # Gaussian noise\n",
    "            img = np.clip(img + noise, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            # Resize image to 28x28 to ensure uniform size\n",
    "            img_resized = cv2.resize(img, (28, 28))\n",
    "            \n",
    "            # Save the generated image to a file with the character label\n",
    "            output_filename = os.path.join(output_dir, f\"{char}_{i}.png\")\n",
    "            cv2.imwrite(output_filename, img_resized)\n",
    "            \n",
    "            # Flatten and add to the dataset\n",
    "            images.append(img_resized)\n",
    "            labels.append(char_to_index[char])  # Store the corresponding numeric label\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images).reshape(-1, 28, 28, 1).astype('float32') / 255.0  # Normalize\n",
    "    labels = np.array(labels)\n",
    "    labels = to_categorical(labels, num_classes=len(chars))  # One-hot encode labels\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Build the OCR model using CNN\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(len(chars), activation='softmax')  # Output layer for 36 classes\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 3: Train the model\n",
    "def train_model(model, images, labels):\n",
    "    model.fit(images, labels, epochs=20, batch_size=16)\n",
    "\n",
    "# Step 4: Predict characters from a generated image\n",
    "def predict(model, img):\n",
    "    img = img.reshape(1, 28, 28, 1).astype('float32') / 255.0  # Normalize the image\n",
    "    prediction = model.predict(img)\n",
    "    predicted_char_index = np.argmax(prediction)\n",
    "    predicted_char = chars[predicted_char_index]\n",
    "    return predicted_char\n",
    "\n",
    "# Generate training data for digits 0-9 and letters A-Z with added complexity\n",
    "images, labels = generate_training_data(chars='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ', num_samples=100)\n",
    "\n",
    "# Build and train the model\n",
    "model = build_model()\n",
    "train_model(model, images, labels)\n",
    "\n",
    "# Now, let's generate an image with 3 random characters (digits or letters) and test the OCR\n",
    "def generate_image_with_digits(chars='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ', output_dir='generated_images'):\n",
    "    \"\"\"Generate an image with 3 random characters with padding and rotation, then save the image to a file.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    img = np.zeros((28, 84), dtype=np.uint8)  # Image width is enough for 3 characters\n",
    "    \n",
    "    chars_to_predict = random.choices(chars, k=3)\n",
    "    x = 5  # Initial x position for the first character\n",
    "    for char in chars_to_predict:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        char_size = cv2.getTextSize(char, font, 1, 2)[0]\n",
    "        y = random.randint(char_size[1], 24)  # Random vertical position\n",
    "        \n",
    "        cv2.putText(img, char, (x, y), font, 1, (255,), 2, cv2.LINE_AA)\n",
    "        x += 28  # Move x for the next character\n",
    "    \n",
    "    # Apply random padding to the whole image\n",
    "    img = cv2.copyMakeBorder(img, random.randint(0, 5), random.randint(0, 5), random.randint(0, 5), random.randint(0, 5), cv2.BORDER_CONSTANT, value=(0))\n",
    "    \n",
    "    # Apply random rotation\n",
    "    angle = random.randint(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((img.shape[1] // 2, img.shape[0] // 2), angle, 1)\n",
    "    img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Save the generated image with its character label\n",
    "    image_label = ''.join(chars_to_predict)\n",
    "    output_filename = os.path.join(output_dir, f\"{image_label}.png\")\n",
    "    cv2.imwrite(output_filename, img)\n",
    "    \n",
    "    return img, image_label\n",
    "\n",
    "# Generate and save an image with 3 characters\n",
    "img, original_chars = generate_image_with_digits()\n",
    "\n",
    "# Predict each character in the generated image\n",
    "predicted_chars = []\n",
    "for i in range(3):\n",
    "    char_img = img[:, i*28:(i+1)*28]  # Extract each character's 28x28 part\n",
    "    char_img = cv2.resize(char_img, (28, 28))  # Resize each character if needed\n",
    "    predicted_char = predict(model, char_img)\n",
    "    predicted_chars.append(predicted_char)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Original Characters: {original_chars}\")\n",
    "print(f\"Predicted Characters: {''.join(predicted_chars)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb4aaed7-a0d2-4de3-bb59-f7b26ec37e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.4926\n",
      "Epoch 2/25\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1507\n",
      "Epoch 3/25\n",
      "\u001b[1m 790/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.1131"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Build a simple neural network\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=25)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Show the first prediction\n",
    "print(f\"Prediction: {np.argmax(predictions[0])}\")\n",
    "plt.imshow(x_test[0], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "model.save('mnist_model.hadi.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f53b7cc-b638-4a76-a3ca-56ce2277f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_model.hadi.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558f8f8d-9289-4baa-8b21-0b7a470aec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07 01:04:24.579511: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736195664.597309    6905 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736195664.602068    6905 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-07 01:04:24.618556: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-07 01:04:27.715825: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/mnt/Users/UT/Desktop/anaconda4/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('mnist_model.hadi.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfb60e9-e99c-46f1-b5bc-e2ee6a40cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 316 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f134eb491c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Predicted Digit: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAGxCAYAAAAgSbJaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVd0lEQVR4nO3deXBc5Z0u/qfX0/umlnrRZnkn2OVgnGAgYJsEgwJmS9jvjU3AQ+4ANx5gEjyEwiQUTsKESSqETKYGGwgmcDMXfBkgIWZisxQwLAYGmwx4kSxZe7fUq3rv9/cHv3OithZLsqTTLT+fqi6pTy96T7fUj97zfs/7aoQQAkRERCrRqt0AIiI6uTGIiIhIVQwiIiJSFYOIiIhUxSAiIiJVMYiIiEhVDCIiIlIVg4iIiFTFICIiIlUxiGjaPPbYY9BoNMpFr9ejrq4ON9xwAzo6OmakDXPmzMGGDRuU63v27IFGo8GePXsm9DxvvvkmtmzZgkgkMqXtA4ANGzZgzpw5x73f6tWrlddSq9XCbrdj/vz5uPLKK/Fv//ZvKBaLwx5z7P6faLseeOAB7Ny5c1LPJ9uyZUvJ78Wxl6effvqEnp8qj17tBtDst337dixevBipVAqvvfYatm7dildffRUff/wxrFbrjLZl+fLleOutt/CFL3xhQo978803cd9992HDhg1wuVzT07hxmDt3Lnbs2AEASCaTaGlpwc6dO3HllVfinHPOwb//+7/D6XQq93/uuefgcDgm9bPuuecefPe73y3Z9sADD+Cb3/wmLrvssknvw0033YQLL7xw2PaNGzfi0KFDI95GsxuDiKbdkiVLsGLFCgDAmjVrUCgU8KMf/Qg7d+7E9ddfP+JjBgcHYbFYprwtDocDK1eunPLnnSlms3lY+2+66SZs374d3/72t/E3f/M3eOaZZ5TbTjvttEn/rHnz5k36sWOpq6tDXV1dybbW1lbs378f119/vapBT+rgoTmacfIH6ZEjRwB8fgjIZrPh448/xtq1a2G32/HVr34VAJDNZnH//fdj8eLFkCQJ1dXVuOGGG9DX11fynLlcDt/73vfg9/thsVjwla98Be+8886wnz3aobn//M//xLp161BVVQWTyYR58+Zh06ZNAD4/lPT3f//3AICmpiblENLQ53jmmWdw5plnwmq1wmaz4YILLsAHH3ww7Oc/9thjWLRoESRJwimnnIInnnhiUq/hsW644QZ8/etfx+9//3vldQVGPjS3f/9+rF27FhaLBdXV1bjlllvw4osvDtunYw/NaTQaJJNJPP7448prsHr16ilp/7Zt2yCEwE033TQlz0eVhT0imnEHDx4EAFRXVyvbstksLrnkEtx888246667kM/nUSwWcemll+L111/H9773PZx11lk4cuQI7r33XqxevRrvvfcezGYzgM8P6zzxxBO48847cf7552Pfvn244oorEI/Hj9uel19+GevWrcMpp5yChx56CA0NDWhtbcWf/vQnAJ/3OPr7+/HLX/4Szz77LAKBAAAoh/ceeOAB/OAHP8ANN9yAH/zgB8hms3jwwQdxzjnn4J133lHu99hjj+GGG27ApZdeip/97GeIRqPYsmULMpkMtNoT/5/wkksuwUsvvYTXX38djY2NI96nq6sLq1atgtVqxa9//WvU1NTgd7/7HW699dbjPv9bb72F8847D2vWrME999wDACWH/eTQam1tnVC7i8UiHnvsMcyfPx+rVq2a0GNplhBE02T79u0CgHj77bdFLpcT8XhcvPDCC6K6ulrY7XbR3d0thBBi/fr1AoDYtm1byeN/97vfCQDi//7f/1uy/d133xUAxCOPPCKEEOIvf/mLACD+7u/+ruR+O3bsEADE+vXrlW27d+8WAMTu3buVbfPmzRPz5s0TqVRq1H158MEHBQDR0tJSsr2trU3o9Xpx2223lWyPx+PC7/eLq666SgghRKFQEMFgUCxfvlwUi0Xlfq2trcJgMIjGxsZRf7Zs1apV4tRTTx319j/84Q8CgPjJT36ibGtsbCzZ/7//+78XGo1G7N+/v+SxF1xwwbDXZf369cPaZbVaS55vKPl1nCi53Vu3bp3wY2l24KE5mnYrV66EwWCA3W7HxRdfDL/fjz/84Q/w+Xwl9/vGN75Rcv2FF16Ay+XCunXrkM/nlcsXv/hF+P1+5TDS7t27AWDYeNNVV10FvX7sTv9nn32GQ4cO4cYbb4TJZJrwvr388svI5/P41re+VdJGk8mEVatWKW389NNP0dnZieuuuw4ajUZ5fGNjI84666wJ/9yRiHEsLfbqq69iyZIlw4o1rr322hP++QcPHlR6uxPx6KOPQq/XT7q6jyofD83RtHviiSdwyimnQK/Xw+fzKYe2hrJYLMOqu3p6ehCJRGA0Gkd83lAoBAAIh8MAAL/fX3K7Xq9HVVXVmG2Tx5qOHTwfr56eHgDAl770pRFvlw+5jdZGedtED2eNRB4bCgaDo94nHA6jqalp2PZj/ymYKaFQCM8//zwuuuiiEV8bOjkwiGjanXLKKUrV3GiG9hJkXq8XVVVV+OMf/zjiY+x2OwAoYdPd3Y3a2lrl9nw+rwTAaORxqqNHj455v9F4vV4AwL/927+NOi5zbBuPNdK2yXj++eeh0Whw7rnnjtkOOTynow0T9dvf/hbZbJZFCic5HpqjsnXxxRcjHA6jUChgxYoVwy6LFi0CAKVySz6/RvZ//s//QT6fH/NnLFy4EPPmzcO2bduQyWRGvZ8kSQCAVCpVsv2CCy6AXq/HoUOHRmyjHMCLFi1CIBDA7373u5JDaEeOHMGbb745vhdkDNu3b8cf/vAHXHvttWhoaBj1fqtWrcK+ffvwySeflGwf70mkkiQNew1OxKOPPopgMIjm5uYpe06qPOwRUdm65pprsGPHDnz961/Hd7/7XXz5y1+GwWDA0aNHsXv3blx66aW4/PLLccopp+B//I//gZ///OcwGAz42te+hn379uEf//Efx3Uy569+9SusW7cOK1euxN/93d+hoaEBbW1tePnll5VwW7p0KQDgF7/4BdavXw+DwYBFixZhzpw5+OEPf4i7774bhw8fxoUXXgi3242enh688847sFqtuO+++6DVavGjH/0IN910Ey6//HJs3LgRkUgEW7ZsmdAhqVQqhbffflv5/vDhw9i5cydeeOEFrFq1Cv/8z/885uM3bdqEbdu2obm5GT/84Q/h8/nw1FNP4b//+78B4LjVe0uXLsWePXvw7//+7wgEArDb7co/BPPnzweAcY8T/ed//if279+Pf/iHf4BOpxvXY2iWUrtagmYvuWru3XffHfN+69evF1ardcTbcrmc+Md//EexbNkyYTKZhM1mE4sXLxY333yzOHDggHK/TCYj7rjjDlFTUyNMJpNYuXKleOutt4ZVjY1UNSeEEG+99ZZobm4WTqdTSJIk5s2bN6wKb/PmzSIYDAqtVjvsOXbu3CnWrFkjHA6HkCRJNDY2im9+85vilVdeKXmOf/3XfxULFiwQRqNRLFy4UGzbtm3E6rSRrFq1SgBQLlarVcydO1d885vfFL///e9FoVAY9phj918IIfbt2ye+9rWvCZPJJDwej7jxxhvF448/LgCIjz76SLnfSO368MMPxdlnny0sFosAIFatWlXys8azH7KNGzcKjUYjDh06NO7H0OykEWIcpTZENKv9zd/8DX73u98hHA6PWhxCNF14aI7oJPPDH/4QwWAQc+fORSKRwAsvvIB//dd/xQ9+8AOGEKmCQUR0kjEYDHjwwQdx9OhR5PN5LFiwAA899NCwCU6JZgoPzRERkapYvk1ERKpSNYgeeeQRNDU1wWQy4fTTT8frr7+uZnOIiEgFqgXRM888g02bNuHuu+/GBx98gHPOOQfNzc1oa2tTq0lERKQC1caIzjjjDCxfvhy//vWvlW2nnHIKLrvsMmzdunXMxxaLRXR2dsJut484NQwREU0PIQTi8TiCweCULF8CqFQ1l81m8f777+Ouu+4q2b527doRpzvJZDIl0690dHRMeKlnIiKaOu3t7ZOeLPhYqgRRKBRCoVAYNuOvz+cbcfLFrVu34r777hu2vb29fVxTuBAR0dSIxWKor69XJh2eCqqeR3TsYTUhxIiH2jZv3ozbb79duS6/EA6Hg0FERKSCqRwWUSWIvF4vdDrdsN5Pb2/viOuiSJKkzH5MRESziypVc0ajEaeffjp27dpVsn3Xrl1TtlolERFVBtUOzd1+++34n//zf2LFihU488wz8S//8i9oa2vDd77zHbWaREREKlAtiK6++mqEw2H88Ic/RFdXF5YsWYKXXnppzFUuiYho9qnIueZisRicTiei0SiLFYiIZtB0fP5yrjkiIlIVg4iIiFTFICIiIlUxiIiISFUMIiIiUhWDiIiIVMUgIiIiVTGIiIhIVQwiIiJSFYOIiIhUxSAiIiJVMYiIiEhVDCIiIlIVg4iIiFTFICIiIlUxiIiISFUMIiIiUhWDiIiIVMUgIiIiVTGIiIhIVQwiIiJSFYOIiIhUxSAiIiJVMYiIiEhVDCIiIlIVg4iIiFTFICIiIlUxiIiISFUMIiIiUhWDiIiIVMUgIiIiVTGIiIhIVQwiIiJSFYOIiIhUxSAiIiJVMYiIiEhVDCIiIlIVg4iIiFTFICIiIlVNeRBt3boVX/rSl2C321FTU4PLLrsMn376acl9NmzYAI1GU3JZuXLlVDeFiIgqwJQH0auvvopbbrkFb7/9Nnbt2oV8Po+1a9cimUyW3O/CCy9EV1eXcnnppZemuilERFQB9FP9hH/84x9Lrm/fvh01NTV4//33ce655yrbJUmC3+8f13NmMhlkMhnleiwWm5rGEhGR6qZ9jCgajQIAPB5PyfY9e/agpqYGCxcuxMaNG9Hb2zvqc2zduhVOp1O51NfXT2ubiYho5miEEGK6nlwIgUsvvRQDAwN4/fXXle3PPPMMbDYbGhsb0dLSgnvuuQf5fB7vv/8+JEka9jwj9Yjq6+sRjUbhcDimq/lERHSMWCwGp9M5pZ+/U35obqhbb70V//Vf/4U33nijZPvVV1+tfL9kyRKsWLECjY2NePHFF3HFFVcMex5JkkYMKCIiqnzTFkS33XYbnn/+ebz22muoq6sb876BQACNjY04cODAdDWHiIjK1JQHkRACt912G5577jns2bMHTU1Nx31MOBxGe3s7AoHAVDeHiIjK3JQXK9xyyy148skn8dRTT8Fut6O7uxvd3d1IpVIAgEQigTvvvBNvvfUWWltbsWfPHqxbtw5erxeXX375VDeHiIjK3JQXK2g0mhG3b9++HRs2bEAqlcJll12GDz74AJFIBIFAAGvWrMGPfvSjcVfDTcdgGRERHV9FFCscL9fMZjNefvnlqf6xRERUoTjXHBERqYpBREREqmIQERGRqhhERESkKgYRERGpikFERESqYhAREZGqGERERKQqBhEREamKQURERKpiEBERkaoYREREpCoGERERqYpBREREqmIQERGRqhhERESkKgYRERGpikFERESqYhAREZGqGERERKQqBhEREamKQURERKpiEBERkaoYREREpCoGERERqYpBREREqmIQERGRqhhERESkKgYRERGpikFERESqYhAREZGqGERERKQqBhEREamKQURERKpiEBERkar0ajeAiMZHCHFCj9doNFPUEqKpxSAiqgBCCOTzeRSLRWSzWRSLReTzeQghlIDSaDTQaDTQ6/XQaDQwGAzQarXKdfk+ROWGQUSkgon2buQgyufzSCaTyOfzSKfTKBaLKBaLAD4PGZ1OB0mSoNPpYDabodPpoNVqldvG+rkMKVLLlAfRli1bcN9995Vs8/l86O7uBvD5H9R9992Hf/mXf8HAwADOOOMM/OpXv8Kpp5461U0hKmtCCBQKBSQSCeRyOcTjceRyOSQSCeTzeQwODqJQKCCTySjBI38tFArIZrMQQihBJAeO3BMyGo3Q6XQwGo0wGo1wu90wm83weDyQJAkulwt6vR6SJLHHRKqalh7RqaeeildeeUW5rtPplO9/+tOf4qGHHsJjjz2GhQsX4v7778f555+PTz/9FHa7fTqaQ6SasXogci8nFothcHAQXV1dGBwcRE9PD9LpNPr7+5HNZhGLxZDL5ZRgOvbQ3FByz0er1ZZ8tVqtaGhogMvlwty5c+F0OqHX62EymZTgYgiRWqYliPR6Pfx+/7DtQgj8/Oc/x913340rrrgCAPD444/D5/Phqaeews033zwdzSFSjRACuVwO+Xwe8Xgc2WwW/f39SKfTCIVCSKVS6OvrQzqdxsDAADKZDKLRKLLZrNJTSqVSJQFUKBRKekJDx4jkrxqNBlrt50WxWq0WJpMJ/f39sFqtaG9vh8PhQH19Paqrq7FkyRJYLBY4HA6GEaliWoLowIEDCAaDkCQJZ5xxBh544AHMnTsXLS0t6O7uxtq1a5X7SpKEVatW4c033xw1iDKZDDKZjHI9FotNR7OJJm20no8QAtlsFplMBqFQCIlEAi0tLYjFYjhw4ACSySTC4TCy2awy9iMHz7GH4OQAmgy9Xo/e3l5IkoQjR47Abrejo6MDc+bMQTAYRLFYhMPhGBZqRDNhyoPojDPOwBNPPIGFCxeip6cH999/P8466yzs379fGSfy+Xwlj/H5fDhy5Mioz7l169Zh405E5UQIgVQqhVwuh2g0ikwmg0gkgnQ6jd7eXgwODqKvrw+Dg4PK9e7ubqTTaSSTSRQKBeRyuZJDbvJXOYBOpHxbDrZcLodsNot4PI50Oo10Oo36+noEAgHYbDZIkgSTyTSFrwzR8U15EDU3NyvfL126FGeeeSbmzZuHxx9/HCtXrgQw/L8tIcSY/4Ft3rwZt99+u3I9Fouhvr5+iltONLrjhUCxWMTg4CBSqRQ6OzuRSCTQ1taGeDyOlpYWJJNJhEIhZDIZxGIxZexHDqCZaL98VGFwcBBarRaxWAz5fB6HDh1CPp/H3LlzAQAmk4k9I5pR016+bbVasXTpUhw4cACXXXYZAKC7uxuBQEC5T29v77Be0lCSJEGSpOluKtGY5FJpubotEomU9Hy6u7uVHk8qlUIoFFJ6RJlMRun5ZDIZFItF5HK5Ez5JdbLksauBgQF8/PHHSCQSqK+vR1VVFSRJgl6vh17PsztoZkz7b1omk8Ff/vIXnHPOOWhqaoLf78euXbtw2mmnAQCy2SxeffVV/OQnP5nuphAd11jBIB82k6vc2tvbkUgk0N7ejng8jvb2diSTSQwMDJQUG8TjcRQKBeTz+Rnck7ENrdg7ePAgisUijh49imKxiNraWuXEWKKZMOW/aXfeeSfWrVuHhoYG9Pb24v7770csFsP69euh0WiwadMmPPDAA1iwYAEWLFiABx54ABaLBdddd91UN4VowoaO9Qw9hJbJZDAwMKD0fORqt6E9H7ncWi42GDrmI1e4lZtCoYB4PI6+vj589tlnyOVyaGpqgs1mg9Fo5KE5mhFTHkRHjx7Ftddei1AohOrqaqxcuRJvv/02GhsbAQDf+973kEql8Ld/+7fKCa1/+tOfeA4RzYjjHQqTgyiVSqGnpwfJZBJdXV1IJBI4evQoksmkEkSjlVmXa+iMpFAoYHBwEJFIBO3t7TCZTEgkEkpviGNFNBM0Qq2D1CcgFovB6XQiGo3C4XCo3RyqIEIIZYYCuccjB0o0GkU6nVZ6OvL5PvL5PeFwWCk2yOVyyGQyI1a7VeCfFKxWK+rq6rB48WJcddVVqK6uxty5c6HT6ZTzkoiA6fn85UFgmlXG0+PJZDJK4Azt8cjVbj09PUilUkpQDQ4OIpfLKef5yCeWVmLgjCabzaK3txdVVVWIRqOwWCwoFouccYFmBIOIZp1cLqfM4Sb3YOQZC+QAGhwcRDgcRiqVUqre+vv7R+zxyGM8cs9ntoUQ8NdDdNFoFB0dHdDpdJgzZw5MJhPMZrPazaNZjkFEFWmsmQxyuZxSXj1Sj6ejowPJZFIpvz62xyMH0GwLm7EUi0WlxDwUCsFutyOdTiuzeBNNJwYRVSy5pyL3dMLhsDJjQSKRQCgUUgbi5bGedDqtBJA8hc6xPZ6TLYSGGhwcRFtbGyRJQjweh1arhd1u5+E5mlYMIqoIIwWDXCgQiUQQi8XQ2tqKgYEBHDp0CJFIRDn0Jvd45K+pVKqsS6rVlMlk0NfXh6qqKgwODrI3RDOCQUQVQx776e3tVU4gjUaj6OrqQjweR29vLxKJhDKXmxw8cugM/Xqy9niOJ5/PK8GeyWRmZPohIgYRlbWhgSFXrPX29qKvrw/79+9HT0+PEkTyITp5uQUGzsTJK8DKJ/XyNaSZwCCistff349kMonDhw8jHA7jwIEDCIVCaGtrQzQaVf57l8NHHuspxw9QjUajrJxqMpmUxen0ej3MZjO0Wq2yjtBEZDIZdHd3KzM7THbf5eo5OYh4+JJmAoOIysqxH6DFYhGxWAz9/f04cOAAOjo68NlnnyEcDivFCHIAlaNjB/nlJbwNBgMcDgeMRmPJV71er5xEOl5CCMTjccTjcWg0GqRSqUm3V66ey2azFTdLBFUuBhGVnXQ6jWw2i+7ubkQiEXzyySfo6elRekLyeUBy0UGhUFC7yQCg9HQcDgcMBgNcLheMRiOcTieMRqNy3WKxKD2goV8tFsuEe0SDg4M4fPiwsiw4USViEFFZGNoTymQySKVS6OjoQHd3Nz755BN0dHTg6NGjiEajShFCuRx6k6fAMRgMSuBYLBb4/X5YrVblayAQgMlkgtVqhV6vh8FgUHpIOp1OmWR0IoEyMDCAcDiMRCLBEmuqWAwiKhvy8gr79u1DZ2cnPvvsM/T29irVcfF4HJlMRtUBdI1Go6xk6na7IUkSPB4PTCYTfD4fzGYzqqqqYDKZ4HQ6IUmS0hNyu93Q6/WQJEkJnKFfdTqd8jPGSy4uiMfjSKVSyGazJ7R/Wq0WkiTBaDRCr9ezl0UzgkFEqpIDRQihnHx6+PBhHDhwAAcPHkRfX59SDadWAA0NBp1OB6vVCovFoiyvXVtbC5vNhjlz5sBqtcLtdpccgrNYLDAYDLBYLNDpdBMeAxqJ/DpIkqQs+Z3NZk+4p6jVamEwGJQQYi+LZgKDiFSXTqeRyWSwb98+tLS04L333kNbWxvC4TCSyaRy/tBMhZAcFi6XC5IkKT0cj8cDs9kMv98Ps9mM6upqmEwmuN1umEwmZXVTufpN/jDX6/XKQnNT9cEuL2yXyWQQj8eVpShOdLxMq9XCZDIplXxyL41oOjGISHXyDNdyRdyRI0fQ0dGh9IJmytCxHoPBAKfTCZvNhoaGBtjtdtTV1cFmsyEYDMJisShFCFarFQaDATabDTqdbkoDZyzyzBJykE9FldvQqj65R8ReEU03BhGpLhQKoaenBy0tLco0PfI8cNNJ7vk4nU6YTCZ4vV5YLBb4fD6luMBisSg9H4/HA0mS4HQ6YTAYIElSSc/HYDDM2Id2Pp9HNBpVijcymcyUnDtlNptRV1cHv98Pu93OKX5oRjCISFVCCCQSCYTDYeUyODg4rT2hoT0fvV4Pl8sFq9WKxsZGOBwOzJ07Fw6HA4FAAGazeVjPR5Ik1ReMKxaLSgn7VIwNyQwGAzwejxLOBoNhClpLNDYGEakuGo2ip6dH+e9+OkJIo9HA4XBAkqSScmqbzaZcr66uhsVigdfrhdlsht1uh16vh9FoLOnxTEWxwYnK5/MlwZ3JZE44iDQaDSwWCxobG1FbWwuHwwGz2az6vtLsxyAi1cnzw6XT6Wk5P0gukbZarbDZbKirq4Pb7cb8+fPhdDrh9/uVMR9JkpQAkg+9yc9RTuSF/5LJ5JTNLKHRaJTiDJfLBZPJBKPROAWtJRobg4hmLbvdDkmSEAwGYbfbsWjRIrjdbqX4oKamRun5yAUKOp1O6fmUW/gMlc1m0dPTg56eHiQSCaTT6RMKcDmAAoEA/H6/Mh6m1/MjgqYff8tIdUNP6pzK5zObzcp5Pl6vF1/4whfg9XoRDAZhtVqVAJJnNpAfW87ksCkUCiUn+Z5oT1Kv18PhcMDhcMBut8NqtXLaIJoxDCJSncPhQHV1tVKlNdlJOy0WC4xGIwKBABwOBxYtWoSqqirMmTMHTqdTOfFULjqQq90q6cO2UCggmUwiHA6jvb0dHR0dU9IjMpvNaGxsVA5bWq3WinpdqLIxiEh1JpNJCSG5MGAi5MNoJpNJmfHA6/Vi8eLFqKmpQV1dHex2uzIGVMlT1wghkE6nkUwmlQXspmKMyGg0KtVy8vsAlH8PkWYHBhGpSqPRwOfzQZIktLa2KjMoyMsRHO9cIo1GA7/fD6fTiSVLlqCmpgZz586Fy+VSAshmsyknaZZDxduJyGaz6OrqQldXF8LhMKLR6Akte67T6ZRzpRYsWID6+nolsCv5daLKwiAi1ckzEtTU1CAcDqOjowPRaBSFQmHUIJJ7QTqdDm63W/kgraurQ0NDA5xOpzIpqTxLwGxQKBQQi8WUCWLT6fQJncgqL9Bns9ng9XqV6YpYpEAzib9tpDr5g0/u0ZjNZrS2tuLQoUMIhUJIJBLIZrPKh628zEJ9fT1cLhdOPfVU1NTUYOHChaiqqlLOF5IP882m/+xzuRz6+vrQ19eHZDJ5wmNDJpMJ9fX1qKurg8/ng9vtnlXBTZWBQUSqkicD1el0yomlvb29EEIgGo0qK4VqNBrl8JNc2dXQ0ACfz4eFCxfC5/OhtrZWKdmebZN1ymFTLBaRSCSUcD7RGcnlBfycTqcyTldpBRxU+RhEVDZsNhtMJhOWLVuGhoYGzJ8/H5FIZNhCePL0M8FgEA6HAzU1NUo1XCUXIhxPoVBAKpVCd3c3ent7kUwmkclkJv18Wq0WNpsN8+bNQ2NjozLV0WzqQVJlYBBRWZDP6jcajUrxgcPhUKavGboMhFym7Xa7lXOF5MNwszWEhBDKbNtT0SOSx9fkhf3kmRQ4txypgUFEZcdqtSpLastLGwytCpNPtJRPRJWvz+b/5AuFAiKRCPr7+9Hf368ctpxs2bYkSaiurkZdXR0aGxuV1WUZRKQGBhGVlaHrAZlMJrWbUzaKxSJSqRQGBweVarkTWX9o6EwK8vjQbD6sSeWNv3VEFSCXy6G3txd9fX1IJBJIpVInPJPC3LlzMWfOHHi9XjgcDk7pQ6phj4ioAhSLRSSTSaVA4UTmltNoNMoYm1wKL5/AOpsPb1L5YhARVYBcLofu7m50d3cjHo9Pukek1+tht9uVsve6ujrlvCuGEKmFQURUxuSwyefzU1Itp9PplErDqqqqkvn3iNTC3z6iMiYvCT4wMIC2tjZ0dHScUI/IZDKhsbERDQ0NqKmp4UwKVBYYRERlTJ78NZVKIRaLIR6PK7NNTMbQmRTkMvnZfP4VVQYGEVEZy+fz6OnpQXd3t3L+UD6fn3AQyWXxTqcTCxcuRENDA9xuNywWC8eGSHX8N4iojBUKBWVsKJVKIZPJTOqQnFarhcFggNlsVtYd4kwKVC6mPIjmzJmjlIEOvdxyyy0AgA0bNgy7beXKlVPdDKJZIZfLobOzE52dnYjFYkilUpM6iVWSJNTX16OhoQH19fXw+/0MIiobU35o7t133y05bLBv3z6cf/75uPLKK5VtF154IbZv365cl1eDJKLPDa2Wi8fjiMfjyvlDkyHPpCDP4We1WnkCK5WNKQ+i6urqkus//vGPMW/ePKxatUrZJkkS/H7/VP9oollDntInEomgpaUFR48eRTQanXSPyGKxYP78+WhqakJVVRXsdvusn5+PKse0/juUzWbx5JNP4tvf/nbJL/yePXuUhcw2btyI3t7eMZ8nk8koq1LKF6LZTAihVMtFo1HEYjFks9lJ9Yi0Wq0yy7bT6YTZbC6ZSYFhRGqb1iDauXMnIpEINmzYoGxrbm7Gjh078Oc//xk/+9nP8O677+K8884bc12VrVu3wul0Kpf6+vrpbDaR6uSxoaNHj6Kvrw8DAwPI5XIT7g1JkoRAIID6+nrMnz8fjY2NsNvtMJlMDCAqG9Navv3oo4+iubkZwWBQ2Xb11Vcr3y9ZsgQrVqxAY2MjXnzxRVxxxRUjPs/mzZtx++23K9djsRjDiGY1uVouHo8razIVi8UJV8zpdDrYbDY4HA64XC7YbDYYDIZZt4ItVbZpC6IjR47glVdewbPPPjvm/QKBABobG3HgwIFR7yNJEiRJmuomEpWtbDaLtrY2tLe3IxqNIpFITGpsyGw2Y8GCBWhqaoLP54PL5eJyD1R2pi2Itm/fjpqaGlx00UVj3i8cDqO9vR2BQGC6mkJUMYQQEEIo1XKxWAzpdHpSY0OcZZsqxbT8W1QsFrF9+3asX7++ZDLFRCKBO++8E2+99RZaW1uxZ88erFu3Dl6vF5dffvl0NIWoohQKBUSjUYRCIbS0tKCtrW1S5w/p9Xp4PB4EAgEsXrwY8+bNg8vlgtVqZQhR2ZmWHtErr7yCtrY2fPvb3y7ZrtPp8PHHH+OJJ55AJBJBIBDAmjVr8Mwzz8But09HU4gqilwtNzg4qJw/lMvlJrwkuDzLttVqhcvlgsPhUJZWJyo30xJEa9euHXFQ1Ww24+WXX56OH0k0K+RyOXR0dKCjowN9fX2IRCKTqpYzmUyYM2cO5syZg0AggKqqKhYpUNnipKdEZaRQKCCZTCpLPUx2bjl5glPOsk2VgEFEVEaG9ohisRgGBwcn1BuST151u9045ZRTUF9fD4/HA7PZzLEhKlsMIqIycGy1nLzu0ETHhuRKObPZDLfbDafTCaPRCIPBwCCissUgIioDhUIB8XgcoVAIR44cwdGjRydVLSevwNrU1ISGhgZUV1fDbDZzKXAqazxgTFQGhBBIp9NIpVKIx+NIJBKTqpbT6/XK2JDNZoPFYuEs21T2+G8SURmQ55Zrb2+fVLXc0BVYTz31VDQ0NKCmpgY2m40hRGWPQURUBorForISazqdnnC1nDw2ZLFYlLEheeE7zqRA5Y5BRFQG5Go5ed2hiVbLmUwmNDQ0oLGxEfPnz0dNTQ2sVitXYKWKwCAiUpEQAsViEfl8XukRTaZaTh4bcrlcsNvtXIGVKgqDiEhFQ6vlWltblWq5ifSI5KUeTjnlFDQ0NMDv98Nut0On0/GQHFUEBhGRiuRqucHBQSQSCSSTSeRyORQKhXE9XqvVlpw35HK5YDKZYDQaOTZEFYNBRKSiE12JVZIkNDQ0oKGhAQsXLoTP54PNZlOCiKgS8AAykYrkarl4PI50Oo1sNjuhajmdTqesvupwOGC1WrnwHVUc9oiIVCSvxNrW1oaBgYEJrcSq0WhgtVqxePFiNDY2wu/3w+FwMIio4jCIiFQghEChUEAulxs2t9x4ekTyCawmk0k5b8hsNnNsiCoSg4hIBfl8Hn19feju7sahQ4eU2bZTqdS4gkiSJNTW1qK+vh6LFi1SekMcG6JKxP47kQqKxaKy7pBcLZfP5ydUsu1wOOB0Ojk2RBWPPSIiFeRyOeW8oZ6englXy5nNZixevBgNDQ0IBoMcG6KKxiAimkHyukO5XA6xWAzRaHTCK7Hq9Xpl8TuXywWz2QxJkjg2RBWLQUQ0g4QQGBwcRCQSwWeffYa2tjaEw+FxV8sZjUb4fL5hY0NyEBFVIvbjiWZQsVhEJpNBKpVCLBabcLWcTqeD3W6Hw+GAw+GAzWaDwWCATqebgdYTTQ/2iIhmUD6fR0dHBzo7O9HZ2Ym+vj6k0+lxT3JqMpmwYMECNDQ0IBAIwOVycWyIKh6DiGgGyTMpyKXa6XQaxWJx3L0hSZLgcrmUsSGeN0SzAYOIaAZls1m0traira0NoVAIsVhsXGNDBoMBHo8HwWAQX/jCFxAMBuF2u2EymdgboorHIKJZTe5pyOv+yFVrx94GoOT2Y+839PpY5J7J0K8ajUZ5fDQaRX9/PyKRCDKZzLjHhrRaLcxmMywWi9ITkmdmkGfqPradcsAd23a5TTqdDjqdDgaDAVqtlj0rUg2DiGa9fD6PQqGAWCyGXC6HbDaLYrGoBE8mk0GhUMDg4CDy+TzS6TQKhQIymYxSXFAoFEoedyz5g12r1SpjNvIHvMFgUJZ7iMVieOeddxAOhzEwMKD8jOMxGAwIBAKoqalRKu8OHz4MAEoYye2T2zv0q7z4ntw+k8kEr9cLp9OJpqYmSJIEq9U65a890XgwiGhWGfqffzabRaFQQDKZRDabRX9/vzLD9dAgkosFhgZRPp8f9oEuP9/xgmhoAMlfASCVSiGRSKC/vx+xWGxCMynIPZV8Po9oNIpsNotEIgEAw9onX5cDVR6HkoNInqMulUohmUzCbreXVN9xQT2aaQwimnXkCUXb2toQiUTwl7/8BeFwGF1dXUooDT0MJweCvF2+PvSrfL/RDtNpNBrl8Jb8Qa7VaqHVaqHT6ZSeVy6XU2ZRGO+SDzqdDoVCAT09PYhGowiFQtBqtUo75HCUv47W/mKxqLRPr9fDZrPB4/HglFNOQW1tLc4++2zYbDa43W4GEc0oBhHNCvKHcrFYVGYq6OnpQTgcRnt7O0KhELq7uzE4OKhMpSOHwNAP8GM/2IeOLcljMaP1YuQgkosHjr0uH0KTeywTWXdI3q9cLodcLqdsG9o+uZcnP/exX4UQyjiQXq9HKpVCNpuF3W6HVqtFX18f8vk8bDYbe0Y0oxhENGvIAbRv3z709PRg79696O7uRnt7O+LxeMnEokNDYKLfj9exH+LHFhGMlxyMfX19Iz7vse07tq0jtV0OpP7+fvT396O1tRWpVAqNjY0499xz2TOiGcUgolkjk8kgmUyir68PXV1d6O7uRm9vLyKRCAYHByfVEykX8qHB6XjeeDwOSZLQ1dUFq9WKVCoFo9E45T+LaDQMIpoVisUienp60Nvbi71796KlpQWHDx9WBvYrNYCmm1zMUSwW8dFHHyGXy+FLX/oStFotampq1G4enSR4JhzNGslkEpFIRLlUei9opsizgcvrIsljR0PHn4imE3tENCsUi0V0dHTgs88+Q3t7O7q7u5FKpZQCAxpbPp9HPB5HJBJBKBSCyWRCJpOBwWBQys+Jpgt7RDQrCCGU83Tk/+gZQuMnV9fJl2NnoSCaTgwimjUGBgbQ09ODeDyOVCo14eq0k50cOkOn+mHVHM0EHpqjWUH+j14+V4djGxMz9ERXg8GgTFPEIKKZwCCiWSOfz5cEEY2fwWCA0+mEx+OB2+2G3W6HXq/ngns0I3hojmYNvV4Po9GozPlG46fX6+FwOGC325XZvfka0kyZ8G/aa6+9hnXr1iEYDEKj0WDnzp0ltwshsGXLFgSDQZjNZqxevRr79+8vuU8mk8Ftt90Gr9cLq9WKSy65BEePHj2hHaGTm0ajgdvths/ng8PhgNls5n/zE2C327F06VIsXrwYPp8PLpeLh+Zoxkw4iJLJJJYtW4aHH354xNt/+tOf4qGHHsLDDz+Md999F36/H+effz7i8bhyn02bNuG5557D008/jTfeeAOJRAIXX3wxq5xo0jQaDSwWC+x2O0wmk2r/0csD/ZP5AJcnSDUYDDAajZAkacSL0WhUxnHksZyJ7qs835wkSXA6naiqqoLP50NVVdWwlV8ZRjTdJjxG1NzcjObm5hFvE0Lg5z//Oe6++25cccUVAIDHH38cPp8PTz31FG6++WZEo1E8+uij+O1vf4uvfe1rAIAnn3wS9fX1eOWVV3DBBRcMe95MJoNMJqNcj8ViE202zXIajQaBQAD5fB7//d//jXg8jnQ6rUwQOhP0en3JJKdDZ70+Ho1GA5PJBL1eD7vdrhQOjDRfnby+klyiPvTreH+efCjO5XJhwYIFqK+vx1e+8hVUVVXB4/FAr+fwMc2cKf1ta2lpQXd3N9auXatskyQJq1atwptvvombb74Z77//PnK5XMl9gsEglixZgjfffHPEINq6dSvuu+++qWwqzTIajUaZqNPj8SASiSCRSKBQKExo3Z+hzzd0WQe5tzL0q9wbGfpVXrROnqlgPPPDaTQaZSlws9mMqqoqpcdzbI9EngVBXrbieEE00uzhwOd/l263Gy6XC42NjQgEAvB4PCxSIFVMaRB1d3cDAHw+X8l2n8+HI0eOKPcxGo1wu93D7iM//libN2/G7bffrlyPxWKor6+fyqZThdNqtairq4Pb7UZPTw+8Xi90Oh16e3sRDocnNNWPfKhLXizO4XDAaDTC6XQqv7uSJMHj8cBkMpUERyqVwjvvvINQKIRPP/0Ug4ODY5aSazQaGI1GuFwunH322aiursaiRYtgMplgMBhGPCwmP58csPJ+yaE39GcVCgVl+Qj58Ljc+6qpqYHNZkMgEIDVakV1dbVSvk00k6al/z3S4YTjHWce6z7ysXGisRiNRhSLRVRXVyOXy6G3t1f53Rlp3jm5tyGvuzN0iW+dTjcsiBwOByRJgsvlUoJI/qrX61EoFBCPx5WVWcczM4FWq1XGtnw+H2pqahAIBCBJ0nGDaGhPZ2hP6NggklellVd0lYNIHg/yeDwwGo0l42ocF6KZNKVB5Pf7AXze6wkEAsr23t5epZfk9/uRzWYxMDBQ0ivq7e3FWWedNZXNoZOMyWSCJElYtmwZ5s+fj6amJsRiMbS1tSEejyMUCinLgAshlF6M3W5XejySJCnBYzabodfrYTKZoNPpIEmScl2v1yu3WywWFItFtLe3KwvYxeNxZUXWscLIYDCgvr4etbW1OO200+Dz+dDY2KgUC4xltOc9dm0i+dyqbDYL4K8nr0qSVDIWxXJtUsuUBlFTUxP8fj927dqF0047DQCQzWbx6quv4ic/+QkA4PTTT4fBYMCuXbtw1VVXAQC6urqwb98+/PSnP53K5tBJRO7dCCFgsVig0+lQXV2thEQikYDVah0xiGw2W8mhN4fDAYPBoHxQyz0FuacjSRK0Wq1yzpIkScjlcshkMhgcHFQW6BvP7A46nU4pGrDZbLBarUpVnLxfJ6JYLEKn06FYLJYccpP3Z+hYGJFaJhxEiUQCBw8eVK63tLTgww8/hMfjQUNDAzZt2oQHHngACxYswIIFC/DAAw/AYrHguuuuAwA4nU7ceOONuOOOO5QKnTvvvBNLly5VquiIToTVaoXFYoHNZkOhUEBjYyNyuRxSqZRScQZAKTqQA2Voz0e+begH9LHzrw39mslk0Nraira2NvT09KC/v18JvLEYjUbMnTsXDQ0NqK6uhtPpnNJCAfmQI4CSIGLwUDmZcBC99957WLNmjXJdLiJYv349HnvsMXzve99DKpXC3/7t32JgYABnnHEG/vSnP8FutyuP+ad/+ifo9XpcddVVSKVS+OpXv4rHHnuMlTp0wob2jOSxHnkcxWg0lkz/IweN3NM59ut4zqGRD32l02llHSR5TGasSj2NRgNJkmCxWOByuZTDgiNVyp3o6zHS90TlRCMqcGbIWCwGp9OJaDQKh8OhdnOoDB07TnLstqHG+rA+3od3Pp9HX18fQqEQnnrqKbS1tWHfvn1IJpNj9ogMBgPq6uoQCARwzTXXoLa2FosXL1Z6ZQwNKlfT8fnLs9ZoVpqpnoAQAolEArFYDPF4XAmg440PDR0bstvtyrgWCwboZMQgIjoB+XwebW1t6OjoQHd3N0KhkFImPhaj0Yj58+ejoaFBOZl0tHJtotmOQUQ0CfK4UzabRSQSwcDAgHKu0lg9IfkEVovFoiy5cOzcbkQnGwYR0SQIIZBOpxGLxXDw4EEcOXIEfX19iMViY/aGdDodvF4v/H4/Fi1ahNraWiWMeFiOTlb8zSeaBHlOuUQigXg8jng8rpw4OhadTge73Q6n0wm73Q6r1arM6EB0smKPiGgS8vk8urq60NXVhY6ODvT09Chzuo3FYDBgzpw5qKurg9/vR1VVlXIeE9HJikFENAlCCMRiMUQiEQwODiKdTh93hm/5HCW5Ws5sNkOSJI4N0UmPQUQ0CXK1XGtrK0Kh0HHHhuQTWG02G5qamtDQ0ACPxwObzcbDcnTSYxARTYAQQplTLhqNIhqNjmtyU61WC7PZDKvVqswpJ6/7w94QnewYREQTUCgUEAqFEAqF0NLSgiNHjiAajSKVSo15aE6n06GmpgbBYBCBQAA1NTXKLN5EJzseEyCaACEE4vG4sgLs4OBgyfx1o9FqtbDb7XA4HMrYEGe9Jvoc/x0jmoB8Po/29nYcPXpUmWVbXqJ7LAaDAbW1tcrYkN1uZ6Uc0f+PQUQ0DsfOpNDf3z+umRQAQK/XKyu7ulwumEwmzqRANASDiGgchBDKyquHDx9GS0sLwuEwEonEmNVyWq0WVqsVLpdLWXfI7XbDarWyWo7o/8e/BKJxkGdSkGfZTiQS45pJQavVwmazweFwlFTLMYSI/oo9IqJxKBQK6OnpQVdXF7q7u9HX1zeumRT0ej1qa2tRW1uLQCAAr9fLmRSIjsEgIhqHYrGIWCyGaDQ67pkU5GW6XS6XMrEpq+WIhmMQEY1DoVBAR0cHWltbEQ6HEY/Hx1WybTKZlJkUqqqqYLfbeViO6BgMIqIxDJ1JIRKJIBKJIJ1OI5fLjRlEcpGC3W6Hy+WC0+mEJEnQ6/XsDREdg0FENIZisYiBgQH09/fjyJEjaG1tndBMCoFAAI2NjaitrYXNZlMmOSWiv+IxAqIxFItFZSaFeDyOZDKJfD4/rsNy8tiQzWaD2WzmvHJEo2CPiGgMhUIBnZ2d6OjoQG9vrzKTwvGCyGAwoKGhAQ0NDaipqYHb7eZhOaJRMIiIRiCEQLFYRC6XQyQSQTgcRjKZRCaTGTOE5OUerFYrqqqq4PF4YDabOZMC0RgYRESjyGazGBwcxJEjR3D48OFxVctptVq43W5UV1dj/vz5qK+vh8vl4kwKRGPgXwbRCIrFIpLJJGKxmDKbQjabRaFQGHNuOZ1OB5fLhaqqKmU2Bc6kQDQ29oiIRlAsFtHX14fe3l50dnaiu7tbmUlhrCDS6/VobGxEXV0dgsEgvF6vchIrEY2MQUQ0AiEEYrEY+vv7kUwmkU6nx+wNaTQaGI1GWK1WVFdXo6amBlarFSaTiWNDRMfBICIagVwt19railAohGg0inw+P+r9tVotnE4nvF4vFi1apMykYLPZ2BsiOg4GEdEQ8kwKyWRSOZE1lUodd/E7+byhqqoquFwu2O12GAwGzitHNA4MIqIh5MlNBwYGlJkUIpEIBgcHx6yW0+v1qKurQ319PYLBIKqrqyFJEmfZJhoHBhHREEIIxONxDAwMIBaLIZFIKDMpjNYjMhqNsFgs8Pl88Pl8ykwK7A0RjQ+DiGiIYrGIrq4udHR0oKenB+FweMyTWLVaLex2OzweDxYuXIjGxkZ4vV6ODRFNAIOICKUzKQwMDCAUCo1rJgW5SEEeG3I4HDAYDJxXjmgCGERE/79cLodUKoX29vaSmRTGWg5cXoE1GAwiGAyipqaGY0NEE8QgIsLnPaJEIoFoNIpIJIJoNIpsNot8Pj/q2JBer4fJZEJ1dTX8fj9sNhtMJhPHhogmiEFEhM/HhsLhMPr6+tDV1YXu7m4kk8lRZ1LQaDQwmUyw2+2YN28e5syZA6/XC7vdzt4Q0QRxNJUInwdRJBJBKBRCPB5HKpUacyYFeWzI4/HA7XbD6XTCaDRCr+f/dkQTxb8aIvy1Wu7IkSMlMymMFkQ6nQ5+vx+BQAC1tbXw+Xwwm81cc4hoEibcI3rttdewbt06BINBaDQa7Ny5U7ktl8vh+9//PpYuXQqr1YpgMIhvfetb6OzsLHmO1atXK/NvyZdrrrnmhHeGaKKEEEin00gmk+jv70coFMLg4OBxS7YNBgO8Xi98Ph/sdjssFgvHhogmacJBlEwmsWzZMjz88MPDbhscHMTevXtxzz33YO/evXj22Wfx2Wef4ZJLLhl2340bN6Krq0u5/OY3v5ncHhCdACEEkskkIpEI2tvbxzWTgk6ng8lkQmNjI+bNmwev1wuHw8HDckSTNOG/nObmZjQ3N494m9PpxK5du0q2/fKXv8SXv/xltLW1oaGhQdlusVjg9/sn+uOJptTQmRTi8bhSoDDaTAparRYOhwNut1tZgdVkMsFgMHCWbaJJmvZihWg0Co1GA5fLVbJ9x44d8Hq9OPXUU3HnnXciHo+P+hyZTEZZoEy+EE2FYrGIUCiEzs5OhEIhDAwMIJvNjnlYrrq6GrW1taivr0dtbS2sViskSWIIEU3StB5LSKfTuOuuu3DdddfB4XAo26+//no0NTXB7/dj37592Lx5Mz766KNhvSnZ1q1bcd99901nU+kkJYRANBotWXdorJkUdDodqqqqUFNTA4fDAavVynJtohM0bUGUy+VwzTXXoFgs4pFHHim5bePGjcr3S5YswYIFC7BixQrs3bsXy5cvH/Zcmzdvxu23365cj8ViqK+vn66m00mkWCyit7cXR48eRSQSQTKZHHMmBZ1Oh9raWsyZMwfV1dVwuVzKYTkimpxpCaJcLoerrroKLS0t+POf/1zSGxrJ8uXLYTAYcODAgRGDSJIkSJI0HU2lk5QQAqlUati6Q2OdwGo2m+F0OlFdXY3q6mpYLBYYjUaODRGdoCkPIjmEDhw4gN27d6Oqquq4j9m/fz9yuRwCgcBUN4doRPJS4JFIBJ2dnejs7EQ8Hh/10Jy88J3X60VDQwMaGhrgcDiU5R6IaPImHESJRAIHDx5Urre0tODDDz+Ex+NBMBjEN7/5TezduxcvvPACCoUCuru7AQAejwdGoxGHDh3Cjh078PWvfx1erxeffPIJ7rjjDpx22mk4++yzp27PiMYgL4AnT2yaTCbHPIFVq9XC4/GguroaTqcTNpuNJ68STZEJB9F7772HNWvWKNflsZv169djy5YteP755wEAX/ziF0set3v3bqxevRpGoxH/8R//gV/84hdIJBKor6/HRRddhHvvvZeDvjRjhBBKtVw4HEY0Gh31sBzw15kU6uvrlbEho9HI3hDRFJhwEK1evXrUP1YAY94GAPX19Xj11Vcn+mOJpoT8+1koFBCJRBAOh49bLWcwGGA2m1FTUwO/3w+73c4VWImmEP+do5OOvAheX18fOjo6EI1GR51JQZ5l22azoaGhAU1NTXC73VyBlWgKcU4SOukMDg4qsykMDAyMWS03tEhh6CzbXIGVaOowiOikIhcp9Pf3o6enBz09PRgcHBx1NgV5JoVAIICamhpUVVXBZDJxPJNoCjGI6KQihChZd2g81XJutxvV1dXK2BDPGyKaWjzITScVIQTC4TA6OzvR39+PWCx23Go5n8+H2tpaOJ1OTulDNA3YI6KTghACQgjk83kMDAwgFAohkUiMWi0nz6TgcDjg9Xrh9XpLZlIgoqnDHhGdNIrFIvL5vHL+UCwWQyqVGjWIHA4HPB6PshKrPMs2q+WIphZ7RHRSkBfAG1otl06nlbWHjiVXyw2dScFgMDCEiKYBg4hOCvLccv39/ejt7UVfX59SLTda2bbX64Xf74fH44HT6eQs20TThEFEJwW5Wq6vrw+xWEyplhuJVquFwWBAVVUVfD4f7HY7TCYTZ1IgmiY8zkAnBblarqurC5FIBIlEYtSybTmI5Go5h8MBi8XCw3JE04Q9IprV5Ol8crmcchJrPB4/bpGCy+VCVVUVPB4PTCYTZ9ommkb8F49mvUKhgGw2i76+PnR1dSnVciOtxKrVauF0OpXlwI9dAI+Iph57RDSrCSEQj8cRi8VKquXGOizn8Xjg8/ngcDiUE1gZQkTThz0imtXkIAqHwwiHw8ddEnxotZzL5VIWwCOi6cO/MJrVhBAYGBhAb28votEokskkCoXCiCE0dN2hYDBYshQ4e0RE04c9IprVhgbRWGXbGo0GRqMRZrMZfr9fmVuO1XJE0489IpqVhBBKkUIoFEJXV5eyAN5IRQoajQYulwsejwcej0dZCpzjQ0TTj//q0ayVz+eRyWTGNbfc0Cl95CCSJIlBRDQD2COiWUkuUohGo+jv70ckEjlutZzX60UgECg5gZUhRDT9GEQ0K8lzy8mVcgMDA8hkMmNO61NVVQW/36+MDXHdIaKZwSCiWUkuUuju7kYsFht1bAgALBYL7Ha7styDzWZT5pYjounHvzSadeRF8IZWy41VpGC1WuFwOODz+eD3+0smOSWi6cceEc0qQgjkcjlkMhn09fWhs7NzzGo5eSaFmpoauN1uZbkHhhDRzGEQ0ayTz+eRTqcRCoWUQ3NjzS3ndruVILLb7QwiohnGIKJZRQiBaDSKSCRSUqQw0mwKGo0Ger1emUmBJ7ASqYN/cTSrDJ1bbmBgANFoVAmiY2m1Wuj1eqVazm63M4iIVMAeEc0qQgj09/eju7t7XDMpyEUKNTU1ynIPDCKimcUgollBPuwmH5rr6+tDIpEYdWxIo9HAbrfD4/GgqqoKVVVVMJvNMBgMPImVaIYxiGjWSKVSSKVS6OzsRFtbGwYGBsaslquurkYgEIDH44HD4WAIEamEQUSzRiaTQSKRGLYS62hzy7ndbvh8PjidTthsNs4rR6QSBhHNCsViEeFwGKFQCKFQSKmWKxaLw6rl9Ho9TCYTAoEA6uvr4Xa7OaUPkYoYRFTRhoaMPDYUiUQQj8eRy+VG7A3p9XpIkqSsxGq325UF8Iho5vEvjyqeEAL5fB69vb1oa2tDf38/EonEqAvg2e12uN1uuFwuOJ1OrjtEpDL2iKjiFYtF5PN5pWx7rLEhjUajTHJqs9lgtVphMBh4WI5IRQwiqmhyuXY8Hkd3dze6u7sRj8eV8aFjaTQaOJ1OVFVVwWq1QpIkHpIjUhmDiCpeMpnEwMAAwuEwwuEwUqkUstnsiAvgybNtO51OmM1mGI1GHpIjUhn/FaSKJoRAOBxGR0cH+vv7EYvFRg0h4PMgcrvdqK6u5rpDRGWCPSKqSMfOpBAKhRCLxZBMJkddAA/4PIhsNhtcLhfMZjMPzRGVgQn/Bb722mtYt24dgsEgNBoNdu7cWXL7hg0boNFoSi4rV64suU8mk8Ftt90Gr9cLq9WKSy65BEePHj2hHaGTTy6XQzqdRk9PjzKTQjKZHHU5cIPBAJPJBI/Ho/SIGERE6pvwX2AymcSyZcvw8MMPj3qfCy+8EF1dXcrlpZdeKrl906ZNeO655/D000/jjTfeQCKRwMUXXzzmf7JEx8rn88hkMspKrPF4HOl0esQiBeDz84eMRiMcDgdcLhdMJhMnOSUqAxM+NNfc3Izm5uYx7yNJEvx+/4i3RaNRPProo/jtb3+Lr33tawCAJ598EvX19XjllVdwwQUXTLRJdBKSD8nJIRQKhZBKpZDP50ctUrDb7cqM2zabjQvgEZWJafkr3LNnD2pqarBw4UJs3LgRvb29ym3vv/8+crkc1q5dq2wLBoNYsmQJ3nzzzRGfL5PJIBaLlVyIkskkIpEIotGoUqQw0gJ4wOdBZDablTWHzGYz9Ho9tFotq+aIVDblQdTc3IwdO3bgz3/+M372s5/h3XffxXnnnYdMJgMA6O7uhtFohNvtLnmcz+dDd3f3iM+5detWOJ1O5VJfXz/VzaYKI4RAKBTC0aNHMTAwMOpMCjKNRgOPxwOfz8cpfYjKzJRXzV199dXK90uWLMGKFSvQ2NiIF198EVdcccWojxNCjPqf6ebNm3H77bcr12OxGMPoJDW0Wi4WiyEcDiORSCCdTo+rWm7o+UMMIqLyMO3l24FAAI2NjThw4AAAwO/3I5vNYmBgoKRX1Nvbi7POOmvE55AkCZIkTXdTqULI6w51dHSgpaUF4XB4zGo54PNlHzweDwKBAJxOJ5cEJyoj0/6XGA6H0d7ejkAgAAA4/fTTYTAYsGvXLuU+XV1d2Ldv36hBRDRUJpNBMplEOBxWVmIdq1oOKC1W4PlDROVlwj2iRCKBgwcPKtdbWlrw4YcfwuPxwOPxYMuWLfjGN76BQCCA1tZW/MM//AO8Xi8uv/xyAIDT6cSNN96IO+64A1VVVfB4PLjzzjuxdOlSpYqOaDTy2FBfXx96e3sRDoeVw3KjzaZgNBphNpvhdruVc9d4aI6ofEw4iN577z2sWbNGuS6P3axfvx6//vWv8fHHH+OJJ55AJBJBIBDAmjVr8Mwzz8ButyuP+ad/+ifo9XpcddVVSKVS+OpXv4rHHnuMMyDTcQkhkEgklOl8EokEcrncqCEE/PX8IZvNBrvdDqPRCL1ez2o5ojIx4SBavXr1mH/0L7/88nGfw2Qy4Ze//CV++ctfTvTH00lO7hG1t7ePue6QTJ5t2+12w+FwKMs+MISIygfnmqOKMLRaLh6Po7+/H8lkctTlHmRD1x+Sx4Z0Oh0PyxGVEQYRVYx4PI5kMonOzk4cPXoU0WgUqVTquGXbTqcT1dXVPH+IqEzxL5IqRiqVQjweRyQSwcDAAFKpFHK53Lh7RJxbjqg8sUdEFUEIgUgkgt7eXgwMDBx33SGZ3COSq+VYtk1UfvgXSRUjnU4jHo9jcHDwuCXbMnmOOXnJBxYqEJUf9oioIgghkMvlkMlkkM/nUSwWjxtCVqsVNpsNfr8fwWBQOTzHHhFReeFfJFUMIYQSQOPpCZlMJlgsFjidTmX9IfaIiMoPe0RUETQaDbxeL4DPlw2RK+hyudyIaxBptVrU1tYiEAggGAyiurpa6Q0xiIjKC4OIKoJGo4HVakWhUIDL5YLT6YTJZIJer0exWCwp4dZoNNDpdHC73aipqYHL5YLNZlPWHyKi8sIgooohr6r6xS9+EV6vF2azGZ2dnWhra1MWS9Rqtaivr4fH48HKlStRX1+P2tpaOJ1OGAwGlfeAiEbCIKKKIUkS9Ho9AoEADAYDent7odFoEIvFlGl+dDodAoEAfD4fGhsbUVdXp/Se2BsiKk8MIqoYcpD4fD44HA4YDAZEIhEsW7YMyWQSwOeH5Wpra+FwODBnzhw4HA5YLBZOckpUxhhEVBHkENFqtbDZbMpUPTU1NaipqUE6nVZud7vdyrIPci+KvSGi8sUgooqj1+uh0+ngcrngcDjgdrtLpvkxGo3Q6XQwGAzQ6XTsCRGVOQYRVRSNRqMEi9lsBvD5iatEVLl4vIKIiFTFICIiIlUxiIiISFUMIiIiUhWDiIiIVMUgIiIiVTGIiIhIVQwiIiJSFYOIiIhUxSAiIiJVMYiIiEhVDCIiIlIVg4iIiFTFICIiIlUxiIiISFUMIiIiUhWDiIiIVMUgIiIiVTGIiIhIVQwiIiJSFYOIiIhUxSAiIiJVMYiIiEhVDCIiIlLVhIPotddew7p16xAMBqHRaLBz586S2zUazYiXBx98ULnP6tWrh91+zTXXnPDOEBFR5ZlwECWTSSxbtgwPP/zwiLd3dXWVXLZt2waNRoNvfOMbJffbuHFjyf1+85vfTG4PiIiooukn+oDm5mY0NzePervf7y+5/v/+3//DmjVrMHfu3JLtFotl2H1Hk8lkkMlklOuxWGwCLSYionI2rWNEPT09ePHFF3HjjTcOu23Hjh3wer049dRTceeddyIej4/6PFu3boXT6VQu9fX109lsIiKaQRPuEU3E448/DrvdjiuuuKJk+/XXX4+mpib4/X7s27cPmzdvxkcffYRdu3aN+DybN2/G7bffrlyPxWIMIyKiWWJag2jbtm24/vrrYTKZSrZv3LhR+X7JkiVYsGABVqxYgb1792L58uXDnkeSJEiSNJ1NJSIilUzbobnXX38dn376KW666abj3nf58uUwGAw4cODAdDWHiIjK1LQF0aOPPorTTz8dy5YtO+599+/fj1wuh0AgMF3NISKiMjXhQ3OJRAIHDx5Urre0tODDDz+Ex+NBQ0MDgM/HcH7/+9/jZz/72bDHHzp0CDt27MDXv/51eL1efPLJJ7jjjjtw2mmn4eyzzz6BXSEioko04SB67733sGbNGuW6XESwfv16PPbYYwCAp59+GkIIXHvttcMebzQa8R//8R/4xS9+gUQigfr6elx00UW49957odPpJrkbRERUqTRCCKF2IyYqFovB6XQiGo3C4XCo3RwiopPGdHz+cq45IiJSFYOIiIhUxSAiIiJVMYiIiEhVDCIiIlIVg4iIiFTFICIiIlUxiIiISFUMIiIiUhWDiIiIVMUgIiIiVTGIiIhIVdO6Qut0kedpjcViKreEiOjkIn/uTuV82RUZRPF4HABQX1+vckuIiE5O8XgcTqdzSp6rIpeBKBaL+PTTT/GFL3wB7e3tFb0URCwWQ319PfejDMyGfQC4H+VkNuwDULofdrsd8XgcwWAQWu3UjO5UZI9Iq9WitrYWAOBwOCr6DZZxP8rHbNgHgPtRTmbDPgB/3Y+p6gnJWKxARESqYhAREZGqKjaIJEnCvffeC0mS1G7KCeF+lI/ZsA8A96OczIZ9AKZ/PyqyWIGIiGaPiu0RERHR7MAgIiIiVTGIiIhIVQwiIiJSFYOIiIhUVbFB9Mgjj6CpqQkmkwmnn346Xn/9dbWbNKqtW7fiS1/6Eux2O2pqanDZZZfh008/LbnPhg0boNFoSi4rV65UqcUj27Jly7A2+v1+5XYhBLZs2YJgMAiz2YzVq1dj//79KrZ4ZHPmzBm2HxqNBrfccguA8nwvXnvtNaxbtw7BYBAajQY7d+4suX08r30mk8Ftt90Gr9cLq9WKSy65BEePHp3BvRh7P3K5HL7//e9j6dKlsFqtCAaD+Na3voXOzs6S51i9evWw9+eaa64pm/0Axvc7pPb7cbx9GOlvRKPR4MEHH1TuM1XvRUUG0TPPPINNmzbh7rvvxgcffIBzzjkHzc3NaGtrU7tpI3r11Vdxyy234O2338auXbuQz+exdu1aJJPJkvtdeOGF6OrqUi4vvfSSSi0e3amnnlrSxo8//li57ac//SkeeughPPzww3j33Xfh9/tx/vnnK5PUlot33323ZB927doFALjyyiuV+5Tbe5FMJrFs2TI8/PDDI94+ntd+06ZNeO655/D000/jjTfeQCKRwMUXX4xCoTBTuzHmfgwODmLv3r245557sHfvXjz77LP47LPPcMkllwy778aNG0ven9/85jcz0XzF8d4P4Pi/Q2q/H8fbh6Ft7+rqwrZt26DRaPCNb3yj5H5T8l6ICvTlL39ZfOc73ynZtnjxYnHXXXep1KKJ6e3tFQDEq6++qmxbv369uPTSS9Vr1Djce++9YtmyZSPeViwWhd/vFz/+8Y+Vbel0WjidTvHP//zPM9TCyfnud78r5s2bJ4rFohCi/N8LAOK5555Tro/ntY9EIsJgMIinn35auU9HR4fQarXij3/844y1fahj92Mk77zzjgAgjhw5omxbtWqV+O53vzu9jZuAkfbjeL9D5fZ+jOe9uPTSS8V5551Xsm2q3ouK6xFls1m8//77WLt2bcn2tWvX4s0331SpVRMTjUYBAB6Pp2T7nj17UFNTg4ULF2Ljxo3o7e1Vo3ljOnDgAILBIJqamnDNNdfg8OHDAICWlhZ0d3eXvC+SJGHVqlVl/b5ks1k8+eST+Pa3vw2NRqNsr4T3Qjae1/79999HLpcruU8wGMSSJUvK+v2JRqPQaDRwuVwl23fs2AGv14tTTz0Vd955Z9n1uoGxf4cq7f3o6enBiy++iBtvvHHYbVPxXlTc7NuhUAiFQgE+n69ku8/nQ3d3t0qtGj8hBG6//XZ85StfwZIlS5Ttzc3NuPLKK9HY2IiWlhbcc889OO+88/D++++XzfQgZ5xxBp544gksXLgQPT09uP/++3HWWWdh//79yms/0vty5MgRNZo7Ljt37kQkEsGGDRuUbZXwXgw1nte+u7sbRqMRbrd72H3K9e8mnU7jrrvuwnXXXVcyc/X111+PpqYm+P1+7Nu3D5s3b8ZHH32kHGItB8f7Haq09+Pxxx+H3W7HFVdcUbJ9qt6Ligsi2dD/XoHPP+CP3VaObr31VvzXf/0X3njjjZLtV199tfL9kiVLsGLFCjQ2NuLFF18c9uarpbm5Wfl+6dKlOPPMMzFv3jw8/vjjykBspb0vjz76KJqbmxEMBpVtlfBejGQyr325vj+5XA7XXHMNisUiHnnkkZLbNm7cqHy/ZMkSLFiwACtWrMDevXuxfPnymW7qiCb7O1Su78e2bdtw/fXXw2QylWyfqvei4g7Neb1e6HS6Yf819Pb2DvuPsNzcdttteP7557F7927U1dWNed9AIIDGxkYcOHBghlo3cVarFUuXLsWBAweU6rlKel+OHDmCV155BTfddNOY9yv392I8r73f70c2m8XAwMCo9ykXuVwOV111FVpaWrBr167jruOzfPlyGAyGsn1/gOG/Q5X0frz++uv49NNPj/t3Akz+vai4IDIajTj99NOHdf127dqFs846S6VWjU0IgVtvvRXPPvss/vznP6Opqem4jwmHw2hvb0cgEJiBFk5OJpPBX/7yFwQCAaV7PvR9yWazePXVV8v2fdm+fTtqampw0UUXjXm/cn8vxvPan3766TAYDCX36erqwr59+8rq/ZFD6MCBA3jllVdQVVV13Mfs378fuVyubN8fYPjvUKW8H8DnRw1OP/10LFu27Lj3nfR7ccLlDip4+umnhcFgEI8++qj45JNPxKZNm4TVahWtra1qN21E/+t//S/hdDrFnj17RFdXl3IZHBwUQggRj8fFHXfcId58803R0tIidu/eLc4880xRW1srYrGYyq3/qzvuuEPs2bNHHD58WLz99tvi4osvFna7XXndf/zjHwun0ymeffZZ8fHHH4trr71WBAKBstoHWaFQEA0NDeL73/9+yfZyfS/i8bj44IMPxAcffCAAiIceekh88MEHSjXZeF7773znO6Kurk688sorYu/eveK8884Ty5YtE/l8viz2I5fLiUsuuUTU1dWJDz/8sORvJZPJCCGEOHjwoLjvvvvEu+++K1paWsSLL74oFi9eLE477bSy2Y/x/g6p/X4c73dKCCGi0aiwWCzi17/+9bDHT+V7UZFBJIQQv/rVr0RjY6MwGo1i+fLlJaXQ5QbAiJft27cLIYQYHBwUa9euFdXV1cJgMIiGhgaxfv160dbWpm7Dj3H11VeLQCAgDAaDCAaD4oorrhD79+9Xbi8Wi+Lee+8Vfr9fSJIkzj33XPHxxx+r2OLRvfzyywKA+PTTT0u2l+t7sXv37hF/h9avXy+EGN9rn0qlxK233io8Ho8wm83i4osvnvH9Gms/WlpaRv1b2b17txBCiLa2NnHuuecKj8cjjEajmDdvnvjf//t/i3A4XDb7Md7fIbXfj+P9TgkhxG9+8xthNptFJBIZ9vipfC+4HhEREamq4saIiIhodmEQERGRqhhERESkKgYRERGpikFERESqYhAREZGqGERERKQqBhEREamKQURERKpiEBERkaoYREREpKr/D2j2QhzJ63Q2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pretrained MNIST model (assuming you've already trained it)\n",
    "model = tf.keras.models.load_model('mnist_model.hadi.keras')  # Update with your model path\n",
    "\n",
    "# Function to preprocess the screenshot image\n",
    "def preprocess_image(image_path):\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale if it's not already\n",
    "    img = img.convert('L')\n",
    "    \n",
    "    # Resize the image to 28x28 pixels\n",
    "    img = img.resize((28, 28))\n",
    "    \n",
    "    # Invert the image (MNIST images have white background with black digits)\n",
    "    img = Image.eval(img, lambda x: 255 - x)\n",
    "    \n",
    "    # Convert image to numpy array and normalize pixel values (0-1)\n",
    "    img_array = np.array(img) / 255.0\n",
    "    \n",
    "    # Reshape to match the input shape for the model (1, 28, 28, 1)\n",
    "    img_array = img_array.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "# Function to predict the digit in the image\n",
    "def predict_digit(image_path):\n",
    "    # Preprocess the image\n",
    "    img_array = preprocess_image(image_path)\n",
    "    \n",
    "    # Predict the digit\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    # Get the predicted digit (index of the highest probability)\n",
    "    predicted_digit = np.argmax(prediction)\n",
    "    \n",
    "    return predicted_digit\n",
    "\n",
    "# Provide the path to the screenshot you want to classify\n",
    "image_path = '/home/hadi/Pictures/seven.png'  # Update with your screenshot path\n",
    "\n",
    "# Predict the digit in the image\n",
    "predicted_digit = predict_digit(image_path)\n",
    "print(f\"Predicted Digit: {predicted_digit}\")\n",
    "\n",
    "# Display the image\n",
    "img = Image.open(image_path)\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.title(f\"Predicted Digit: {predicted_digit}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
